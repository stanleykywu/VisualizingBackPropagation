# VisualizingBackPropogation

Graphical Representation of a neural network's training using stochastic gradient descent with one hidden layer where loss is squared distance. Includes ability to toggle sigmoid activation and relu activation.

![alt text](https://github.com/stanleykywu/VisualizingBackPropogation/Images%20and%20GIFS/Demonstration.gif)


# VisualizingBackPropogation

Graphical Representation of a neural network's training using stochastic gradient descent with one hidden layer where loss is squared distance. Includes ability to toggle sigmoid activation and relu activation.

![alt text](Demonstration.gif)
